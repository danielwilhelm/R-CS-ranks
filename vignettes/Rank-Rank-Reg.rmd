---
title: "Inference for Rank-Rank Regressions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Inference for Rank-Rank Regressions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

Suppose, that one would like to investigate relationship between two (or more) variables
of interest. However, the focus is not on the interdependence of their absolute values, 
but their ranks - how high/low is a certain value in the population. More specifically, 
the (fractional) rank answer the question *How large percentage of the population has higher
(lower) value of the feature than a certain specified individual*. It is closely related to the
cumulative distribution function (CDF).

A classic example is investigating intergenerational mobility - the link between the economical status
of parents and children. Put simply, are the adult kids of rich parents also rich?

## Rank-Rank regression

Denote by $X$ the explanatory variable, $Y$ the outcome variable, and by 
$F_X, F_Y$ CDFs of $X$ and $Y$. We postulate a linear model between
$R_X=F_X(X)$ and $R_Y=F_Y(Y)$:

\[R_Y = c+\rho R_X\]

A naive course of action would be to estimate $R_X$ and $R_Y$ using the empirical 
cumulative distribution function and plug the results into `lm`. However, this approach
ignores the uncertainty originating from rank estimation. An individual 
with income larger than 90% of sample could have income larger than 92 or 87% of the whole
population after all. This ignorance results in inconsistent standard errors, confidence
intervals and p-values of regression coefficients $c$ and $\rho$. 

In the `csranks` package, an asymptotically correct method of calculation of those standard errors
is implemented. The key function in the workflow is `lmranks`.

## Example: Intergenerational Mobility

Let's return to the example of investigating the link between economic status 
of parents and children. In `csranks` package there is an artificial dataset
with data about children' and parents' families income, their gender and race (`black`, `hisp` or `neither`).

First, load the package `csranks`. Second, load the data and take a quick look at it:

```{r setup}
library(csranks)
data(parent_child_income)
head(parent_child_income)
```

Consider regression of **rank** of child income (`c_faminc`) on the **rank** of 
parent income (`p_faminc`):

```{r lmranks}
lmr_model <- lmranks(r(c_faminc) ~ r(p_faminc), data=parent_child_income)
summary(lmr_model)
```
These are the results using consistent theory derived in Chetverikov and Wilhelm (2023).
Compare them with naive results:

```{r lm}
c_faminc_rank <- frank(parent_child_income$c_faminc, omega=1, increasing=TRUE)
p_faminc_rank <- frank(parent_child_income$p_faminc, omega=1, increasing=TRUE)
lm_model <- lm(c_faminc_rank ~ p_faminc_rank)
summary(lm_model)
```

The regression coefficients are equal, but the standard errors, t-values and p-values differ.
This difference could actually lead to different decisions based on statistical tests.

## Grouped rank-rank regression

As of version 1.2, the rank-rank regression can be run in two modes. The first is with
(at most) one ranked regressor and other, non ranked, regressors. 
The second is when the data is divided into groups and the interest is in
running a rank-rank regression in each group separately. In `csranks`, this can be done easily
using the interaction notation:

```{r grouped_lmranks}
parent_child_income$subgroup <- interaction(parent_child_income$male, parent_child_income$race)
grouped_lmr_model <- lmranks(r(c_faminc) ~ r(p_faminc_rank):subgroup, 
                             data=parent_child_income)
grouped_lmr_model
```

Let's compare the confidence intervals for regression coefficients produced
by `lmranks` and naive approaches.

```{r grouped_lm}
grouped_lm_model <- lm(c_faminc_rank ~ p_faminc_rank:subgroup + subgroup - 1, #group-wise intercept
                       data=parent_child_income)

```

```{r plot_CIs, message = FALSE, out.width = "90%", fig.width=6, fig.height=4}
library(ggplot2)
theme_set(theme_minimal())
ci_data <- data.frame(estimate=coef(lmr_model), 
                    parameter=c("Intercept", "slope"),
                    group="Whole sample",
                    method="csranks", 
                    lower=confint(lmr_model)[,1], 
                    upper=confint(lmr_model)[,2])
  
  ci_data <- rbind(ci_data, data.frame(
    estimate = coef(grouped_lmr_model),
    parameter = rep(c("Intercept", "slope"), each=6),
    group = rep(c("Hispanic female", "Hispanic male", "Black female", "Black male", 
                  "Other female", "Other male"), times=2),
    method="csranks",
    lower=confint(grouped_lmr_model)[,1],
    upper=confint(grouped_lmr_model)[,2]
  ))
  
  ci_data <- rbind(ci_data, data.frame(
    estimate = coef(lm_model),
    parameter = c("Intercept", "slope"),
    group = "Whole sample",
    method="naive",
    lower=confint(lm_model)[,1],
    upper=confint(lm_model)[,2]
  ))
  
  ci_data <- rbind(ci_data, data.frame(
    estimate = coef(grouped_lm_model),
    parameter = rep(c("Intercept", "slope"), each=6),
    group = rep(c("Hispanic female", "Hispanic male", "Black female", "Black male", 
                  "Other female", "Other male"), times=2),
    method="naive",
    lower=confint(grouped_lm_model)[,1],
    upper=confint(grouped_lm_model)[,2]
  ))
  
  ggplot(ci_data, aes(y=estimate, x=group, ymin=lower, ymax=upper,col=method, fill=method)) +
    geom_point(position=position_dodge2(width = 0.9)) +
    geom_errorbar(position=position_dodge2(width = 0.9)) +
    geom_hline(aes(yintercept=estimate), data=subset(ci_data, group=="Whole sample"),
               linetype="dashed",
               col="gray") +
    coord_flip() +
    labs(title="95% confidence intervals of intercept and slope\nin rank-rank regression")+
    facet_wrap(~parameter)
```

The coefficient calculated for the whole sample has a narrow confidence interval, which is
expected. One can notice differences between confidence intervals for the two discussed methods.
They might not look large, but they matter especially in borderline cases - e.g. when
testing a hypothesis whether the effect for one group (*Other male*) is different from
the effect for the whole sample.

## Reference & further reading
Chetverikov and Wilhelm (2023), "Inference for Rank-Rank Regressions"

Check out the documentation of individual functions at package's [website](https://danielwilhelm.github.io/R-CS-ranks/).